# Student Progress Feature Design

## Objectives
- Track completion and mastery across learning quests.
- Surface recommended next steps based on observed behavior.
- Provide dynamic badges and achievements generated by prompt templates.
- Ensure privacy, transparency, and extensibility for future subjects.

## Core Concepts
- **Quest**: Atomic learning unit with objectives, estimated effort, and mastery rubric.
- **Progress Observation**: Stream of events (quest started, checkpoint passed, reflection submitted, assessment scored).
- **Mastery Profile**: Aggregated representation of learner performance per subject and skill dimension.
- **Achievement Engine**: Prompt-driven badge descriptions with metadata for display and sharing.

## Architecture Overview
1. **Event Ingestion Layer**
   - Instrument client interactions to emit structured events via a `ProgressEvent` type (questId, userId, eventType, payload, timestamp).
   - Buffer events locally to support offline mode and replay on reconnect.
   - Persist events server-side in an append-only store (e.g., Firestore collection or Supabase table) to keep audit history.

2. **Progress Tracker Service**
   - Subscribe to the event stream and maintain per-learner quest state machines.
   - Compute completion percentage using quest metadata (required checkpoints, mastery threshold).
   - Update `LearnerProgress` records with timestamps for started/completed, time-on-task, and attempt counts.
   - Trigger mastery recalculations when assessments or reflections arrive.

3. **Mastery Inference Engine**
   - Define a scoring rubric per subject: weights for formative (reflections) vs summative (assessments) evidence.
   - Use Bayesian or exponential smoothing to blend new evidence with historical performance.
   - Map scores to mastery bands (e.g., Emerging, Proficient, Mastery) and store alongside confidence intervals.
   - Expose mastery summaries via API for UI dashboards and AI reasoning.

4. **AI-Orchestrated Recommendations**
   - Feed recent quest outcomes and mastery deltas into the AI planning prompt.
   - Ask the model to suggest next-step quests using available catalog metadata (prerequisites, difficulty, modality).
   - Constrain responses with system prompts that enforce safety, pacing, and alignment to curriculum goals.

5. **Dynamic Badge & Achievement Engine**
   - Maintain badge templates with criteria expressed as logical predicates over progress/mastery metrics.
   - When criteria are met, craft badge narratives via prompt templates that reference learner-specific achievements.
   - Store awarded badges with provenance (event IDs, template version, prompt parameters) for transparency.

6. **Learner-Facing UI**
   - **Progress Overview**: timeline of recent quests, completion percentages, upcoming recommendations.
   - **Mastery Radar**: radial or bar chart per subject showing current band and trend arrows.
   - **Badge Showcase**: gallery of earned achievements with shareable copy.
   - Provide contextual explanations: "You reached Proficient in Geometry because..." using traced events.

## Data Model Sketch
```ts
// Shared Types (types.ts)
export type ProgressEvent = {
  id: string;
  userId: string;
  questId: string;
  eventType:
    | 'quest_started'
    | 'checkpoint_completed'
    | 'reflection_submitted'
    | 'assessment_scored'
    | 'quest_completed';
  payload: Record<string, unknown>;
  timestamp: string;
};

export type LearnerProgress = {
  userId: string;
  questId: string;
  status: 'not_started' | 'in_progress' | 'completed';
  completion: number; // 0-1 range
  timeOnTaskMinutes: number;
  attempts: number;
  lastUpdated: string;
};

export type MasteryRecord = {
  userId: string;
  subjectId: string;
  skillId: string;
  masteryScore: number; // 0-100
  masteryBand: 'emerging' | 'developing' | 'proficient' | 'mastery';
  confidence: number; // 0-1
  trend: 'up' | 'steady' | 'down';
  evidence: string[]; // linked event IDs
  updatedAt: string;
};

export type Badge = {
  id: string;
  userId: string;
  templateId: string;
  title: string;
  description: string;
  icon: string;
  awardedAt: string;
  evidence: string[];
};
```

## Implementation Steps
1. **Event Schema & Instrumentation**
   - Add the `ProgressEvent` type to `types.ts`.
   - Create a `useProgressEvents` hook to queue and dispatch events from UI components.
   - Instrument key quest interactions (start, checkpoint, reflection, assessment submission).

2. **Backend Sync**
   - Create API endpoints (`POST /progress-events`, `GET /progress/:userId`) using Supabase Edge Functions or Next.js API routes.
   - Implement idempotency by deduplicating events based on UUIDs.
   - Schedule jobs to aggregate daily summaries for analytics.

3. **Mastery Calculation Worker**
   - Deploy a serverless worker (Cloud Functions, Workers) that listens to new assessment events.
   - Recalculate mastery using rubric weights and update `MasteryRecord` documents.
   - Log explanations for transparency and debugging.

4. **AI Recommendation Pipeline**
   - Extend `suggestions.ts` with prompt templates that condition on mastery bands and recent badges.
   - Use a `useNextQuestRecommendations` hook to fetch the latest AI suggestions and expose loading/error states.
   - Cache recommendations per learner session to avoid redundant calls.

5. **Badging Logic**
   - Define badge templates (JSON or database) with criteria expressions (e.g., `completed_quests >= 5` AND `masteryBand === 'proficient'`).
   - Evaluate criteria whenever progress/mastery updates occur.
   - Generate badge copy via AI with guardrails to prevent sensitive content.

6. **UI Components**
   - Build reusable cards/charts under `components/progress/`.
   - Ensure accessibility: semantic headings, ARIA roles, keyboard navigation.
   - Provide skeleton states while data loads to maintain perceived performance.

7. **Analytics & Feedback Loop**
   - Capture aggregate metrics (quests completed/week, mastery lift) to monitor effectiveness.
   - Gather learner feedback on recommendations and badge relevance for continuous tuning.

## Privacy & Ethics Considerations
- Allow learners to view and correct their mastery data.
- Offer opt-outs for AI-personalized recommendations.
- Limit data retention for badge prompts to minimize personal data exposure.
- Document evaluation methodology to avoid reinforcing biases.

## Future Enhancements
- Introduce streaks and collaborative quests with shared progress tracking.
- Integrate formative assessment authoring so educators can tweak rubrics.
- Explore knowledge tracing models (e.g., Deep Knowledge Tracing) for richer mastery predictions.
- Add notification system to celebrate milestones in real time.
